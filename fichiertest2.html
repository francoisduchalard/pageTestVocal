<!DOCTYPE html>
<html lang="fr">
<head>
  <meta charset="UTF-8">
  <title>Test Audio + Reconnaissance Vocale</title>
  <style>
    body { font-family: Arial, sans-serif; margin: 20px; }
    button { margin: 5px; padding: 10px; }
    #logs div { margin-bottom: 5px; }
    #transcription { min-height: 50px; margin-top: 10px; border: 1px solid #ccc; padding: 5px; }
  </style>
</head>
<body>
  <h1>Test Audio + Reconnaissance Vocale</h1>

  <button id="start-btn">Démarrer</button>
  <button id="stop-btn" disabled>Arrêter</button>

  <h2>Transcription :</h2>
  <div id="transcription"></div>

  <h2>Logs / Audio :</h2>
  <div id="logs"></div>

  <script>
    const startBtn = document.getElementById('start-btn');
    const stopBtn = document.getElementById('stop-btn');
    const logsDiv = document.getElementById('logs');
    const transcriptionDiv = document.getElementById('transcription');

    let mediaRecorder = null;
    let audioChunks = [];
    let recognition = null;

    function log(msg) {
      const div = document.createElement('div');
      div.textContent = msg;
      logsDiv.appendChild(div);
    }

    // Vérifie si la reconnaissance vocale est supportée
    if ('webkitSpeechRecognition' in window) {
      recognition = new webkitSpeechRecognition();
      recognition.lang = 'fr-FR';
      recognition.continuous = true;

      recognition.onresult = (event) => {
        let texte = '';
        for (let i = 0; i < event.results.length; i++) {
          texte += event.results[i][0].transcript + ' ';
        }
        transcriptionDiv.textContent = texte;
      };

      recognition.onerror = (e) => log("Erreur reconnaissance vocale : " + e.error);
    } else {
      log("Reconnaissance vocale non supportée sur ce navigateur (Chrome recommandé).");
    }

    startBtn.addEventListener('click', async () => {
      // Enregistrement audio
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        mediaRecorder = new MediaRecorder(stream);
        audioChunks = [];

        mediaRecorder.ondataavailable = (e) => audioChunks.push(e.data);
        mediaRecorder.onstop = () => {
          const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
          const audioURL = URL.createObjectURL(audioBlob);
          const audio = new Audio(audioURL);
          audio.controls = true;
          logsDiv.appendChild(audio);
          log("Enregistrement terminé.");
        };

        mediaRecorder.start();
        log("Enregistrement audio démarré.");

        // Reconnaissance vocale
        if (recognition) recognition.start();

        startBtn.disabled = true;
        stopBtn.disabled = false;

      } catch (err) {
        log("Erreur d'accès au micro : " + err.message);
      }
    });

    stopBtn.addEventListener('click', () => {
      if (mediaRecorder) mediaRecorder.stop();
      if (recognition) recognition.stop();

      startBtn.disabled = false;
      stopBtn.disabled = true;
      log("Enregistrement et transcription arrêtés.");
    });
  </script>
</body>
</html>


