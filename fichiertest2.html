<!DOCTYPE html>
<html lang="fr">
<head>
  <meta charset="UTF-8">
  <title>Audio + Transcription avec OpenAI</title>
  <style>
    body { font-family: Arial, sans-serif; margin: 20px; }
    button { margin: 5px; padding: 10px; }
    #logs div { margin-bottom: 5px; }
    #transcription { min-height: 50px; margin-top: 10px; border: 1px solid #ccc; padding: 5px; }
  </style>
</head>
<body>
  <h1>Enregistrement Audio + Transcription</h1>

  <input type="text" id="api-key" placeholder="Ta clé OpenAI">
  <br>
  <button id="start-btn">Démarrer</button>
  <button id="stop-btn" disabled>Arrêter</button>

  <h2>Transcription :</h2>
  <div id="transcription"></div>

  <h2>Logs / Audio :</h2>
  <div id="logs"></div>

  <script>
    const startBtn = document.getElementById('start-btn');
    const stopBtn = document.getElementById('stop-btn');
    const logsDiv = document.getElementById('logs');
    const transcriptionDiv = document.getElementById('transcription');
    const apiKeyInput = document.getElementById('api-key');

    let mediaRecorder = null;
    let audioChunks = [];

    function log(msg) {
      const div = document.createElement('div');
      div.textContent = msg;
      logsDiv.appendChild(div);
    }

    async function transcribeAudio(blob) {
      const apiKey = apiKeyInput.value.trim();
      if (!apiKey) {
        log("⚠️ Renseigne ta clé OpenAI pour la transcription.");
        return;
      }

      const formData = new FormData();
      formData.append("file", blob, "audio.webm");
      formData.append("model", "whisper-1");

      log("Envoi de l'audio à OpenAI pour transcription...");

      try {
        const response = await fetch("https://api.openai.com/v1/audio/transcriptions", {
          method: "POST",
          headers: { "Authorization": `Bearer ${apiKey}` },
          body: formData
        });

        if (!response.ok) throw new Error("Erreur API OpenAI");

        const data = await response.json();
        transcriptionDiv.textContent = data.text;
        log("Transcription reçue ✅");

      } catch (err) {
        log("Erreur transcription : " + err.message);
      }
    }

    startBtn.addEventListener('click', async () => {
      transcriptionDiv.textContent = '';
      logsDiv.textContent = '';

      try {
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        mediaRecorder = new MediaRecorder(stream);
        audioChunks = [];

        mediaRecorder.ondataavailable = (e) => audioChunks.push(e.data);
        mediaRecorder.onstop = async () => {
          const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
          const audioURL = URL.createObjectURL(audioBlob);
          const audio = new Audio(audioURL);
          audio.controls = true;
          logsDiv.appendChild(audio);
          log("Enregistrement terminé.");

          // Envoi pour transcription
          await transcribeAudio(audioBlob);
        };

        mediaRecorder.start();
        log("Enregistrement audio démarré.");

        startBtn.disabled = true;
        stopBtn.disabled = false;

      } catch (err) {
        log("Erreur d'accès au micro : " + err.message);
      }
    });

    stopBtn.addEventListener('click', () => {
      if (mediaRecorder) mediaRecorder.stop();
      stopBtn.disabled = true;
      startBtn.disabled = false;
    });
  </script>
</body>
</html>
